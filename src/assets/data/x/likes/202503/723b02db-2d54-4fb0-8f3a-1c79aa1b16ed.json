{"text": "@threejs Most models have a context window limit of ~128,000 tokens. Your llms.txt has over a million.\n\nThis isn't usable. If you need help getting it right - lmk https://t.co/FVTJgtwLe7", "username": "theo", "tweet_url": "https://twitter.com/theo/status/1905448441934905480", "first_link": "https://x.com/theo/status/1905448441934905480/photo/1", "created_at": "March 28, 2025 at 02:34AM", "embed_code": "<blockquote class=\"twitter-tweet\">\n  <p lang=\"en\" dir=\"ltr\">@threejs Most models have a context window limit of ~128,000 tokens. Your llms.txt has over a million.\n\nThis isn't usable. If you need help getting it right - lmk https://t.co/FVTJgtwLe7</p>\n  &mdash; Theo - t3.gg (@theo)\n  <a href=\"https://twitter.com/theo/status/1905448441934905480\">Mar 28, 2025</a>\n</blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n", "liked_at": "2025-03-28T11:31:53.410777", "source": "ifttt"}